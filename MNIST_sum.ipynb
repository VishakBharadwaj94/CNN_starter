{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9+PWNLwHSouNUysHRJgcJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishakBharadwaj94/CNN_starter/blob/main/MNIST_sum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MP8QAYOOQhf",
        "outputId": "e9cac2c6-98e8-4841-8b4d-1e070eb18bc7"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "\n",
        "train_data = torchvision.datasets.MNIST('./',download=True)\n",
        "train_data.data.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umxEHBmNF5YA"
      },
      "source": [
        "ints = torch.randint(0,9,size=(60_000,))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkF84VFJGOr-",
        "outputId": "d48145bc-770d-41e7-c942-3d4337ce0af0"
      },
      "source": [
        "ints[:10]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 1, 0, 5, 8, 5, 2, 8, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNQ05eY5YN1l"
      },
      "source": [
        "import torch \n",
        "from torch import nn \n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Dataset:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.data = train_data.data.float()\n",
        "    self.targets = train_data.targets\n",
        "    self.ints = ints\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    image = torch.unsqueeze(self.data[idx],0)\n",
        "    int_no = ints[idx]\n",
        "    target = self.targets[idx]\n",
        "\n",
        "    return image,int_no,target,int_no+target\n",
        "    \n",
        "  def __len__(self):\n",
        "    \n",
        "    return len(self.targets)\n",
        "\n",
        "    "
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXbTpBz5ZHV0"
      },
      "source": [
        "train_data = Dataset()"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHmfKE94ZYp3"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "        #addition\n",
        "        self.linear1 = nn.Linear(2,20)\n",
        "        self.linear2 = nn.Linear(20,1)\n",
        "\n",
        "    def forward(self, x,x2):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        out1 = self.fc2(x)\n",
        "\n",
        "        #addition\n",
        "        x1 = torch.argmax(F.softmax(out1),1)\n",
        "        inp = torch.cat((x1[:,None],x2[:,None]),dim=1).float()\n",
        "        out = self.linear1(inp)\n",
        "        out = F.relu(out)\n",
        "        out = self.linear2(out)\n",
        "\n",
        "\n",
        "        return F.log_softmax(out1),out"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4obI54ZseN"
      },
      "source": [
        "network = Net().cuda()\n",
        "optimizer = torch.optim.AdamW(network.parameters(), lr=0.1)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxxe9xN0hFZc"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_data,shuffle=True,batch_size=256)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzoPSrXFhobL"
      },
      "source": [
        "def train(epoch):\n",
        "\n",
        "  network.train()\n",
        "  losses = 0.\n",
        "  for data,int_no,target,sum_int in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    output1,output2 = network(data.float().cuda(),int_no.float().cuda())\n",
        "    loss1 = F.nll_loss(output1, target.cuda())\n",
        "    loss2 = F.mse_loss(output2,sum_int.float().cuda())\n",
        "    loss = (loss1+loss2)/2\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    losses+=loss\n",
        "  print(f\"epoch {epoch+1},Loss {losses}\")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXwbqVE7LaLS",
        "outputId": "a3202e4c-6e4a-4a82-f8bc-7fb2bdb8dc00"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train(epoch)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Using a target size (torch.Size([256])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1,Loss 2038.466064453125\n",
            "epoch 2,Loss 2041.0753173828125\n",
            "epoch 3,Loss 2073.2119140625\n",
            "epoch 4,Loss 2039.6890869140625\n",
            "epoch 5,Loss 2052.438232421875\n",
            "epoch 6,Loss 2045.7342529296875\n",
            "epoch 7,Loss 2061.76171875\n",
            "epoch 8,Loss 2043.4609375\n",
            "epoch 9,Loss 2047.882568359375\n",
            "epoch 10,Loss 2042.280029296875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOHYjtPPpvsy"
      },
      "source": [
        "# IGNORE STUFF BELOW THIS LINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pmDmbfK8pnp"
      },
      "source": [
        "add_sum = add1 + add2"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGt_zhBd5oKB"
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F \n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(2,20)\n",
        "    self.linear2 = nn.Linear(20,1)\n",
        "\n",
        "  def forward(self,x1,x2):\n",
        "    inp = torch.cat((x1[None],x2[None])).float()\n",
        "    out = self.linear1(inp)\n",
        "    out = F.relu(out)\n",
        "    out = self.linear2(out)\n",
        "\n",
        "    return out "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNhL9q1y62z6"
      },
      "source": [
        "net = Net()\n",
        "optim = torch.optim.AdamW(net.parameters(),lr=0.1)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ90_jGE66Sm",
        "outputId": "6ef10742-c729-4305-a4c0-38aef138b54b"
      },
      "source": [
        "for i in range(len(add1)):\n",
        "\n",
        "  out = net(add1[i],add2[i])\n",
        "  loss = criterion(out,add_sum[i].float())\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  if i%500==0: print(loss)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(9.5540, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0009, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0118, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0004, grad_fn=<MseLossBackward>)\n",
            "tensor(0.3194, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0007, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0010, grad_fn=<MseLossBackward>)\n",
            "tensor(3.0294, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0036, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0049, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0087, grad_fn=<MseLossBackward>)\n",
            "tensor(0.0001, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4N2Btg29ZT1"
      },
      "source": [
        "x1 = torch.tensor(5)\n",
        "x2 = torch.tensor(12)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLm05PSD5jzX",
        "outputId": "fa1b97e7-ee2f-4d01-bd8f-5ad9ea9c6633"
      },
      "source": [
        "import torch \n",
        "\n",
        "add1= torch.randint(0,9,size=[6000])\n",
        "add2= torch.randint(0,9,size=[6000])\n",
        "torch.cat((add1[0][None],add2[0][None])).shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZL3wWYf-wlu",
        "outputId": "221dfe24-c3e3-4679-86d3-e2aa34941b8d"
      },
      "source": [
        "net(x1,x2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([17.0277], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}